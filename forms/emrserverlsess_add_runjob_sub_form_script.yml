ScriptS3Bucket: |
  Choose S3 Bucket location
  1. **Spark:**  S3 Bucket where scripts are stored.
  2. **Hive:**  S3 Bucket where the initialization script is stored.
ScriptS3BucketFolder: |
  Specify the S3 folder location.
  1. **Spark:** S3 Bucket where scripts are stored. Example: `samples/wordcount/scripts/wordcount.py`
  2. **Hive:** S3 location of the initialization script that you can use to initialize tables prior to running the Hive script. Example: `hive/create_table.sql`
ScriptArguments: |
  Specify the arguments
  1. **Spark:** Specify array of arguments passed to your main JAR or Python script. Each argument in the array must be separated by a comma. 
    Example:
    ```js
       ["s3://<YOUR_S3_BUCKET_NAME>/wordcount_output", 40000]
    ```
  2. **Hive:** The S3 URI of the main JAR or Python script in S3 which needs to be executed in the job. 
    Example:
   ```js
    s3://<YOUR_S3_BUCKET_NAME>/hive/extreme_weather.sql
  ```
ScriptSubmitParameters: |
  Specify additional configuration properties for your each job.
    1. **Spark:** 
      Example:
      ```yaml
      --hiveconf hive.exec.scratchdir=s3://<YOUR_S3_BUCKET_NAME>/hive/scratch, --hiveconf hive.metastore.warehouse.dir=s3://<YOUR_S3_BUCKET_NAME>/hive/warehouse
      ```
    2. **Hive:** 
      Example: 
     `
      --conf spark.executor.cores=1 --conf spark.executor.memory=4g --conf spark.driver.cores=1 --conf spark.driver.memory=4g --conf spark.executor.instances=1
      `
