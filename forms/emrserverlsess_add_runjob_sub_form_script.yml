ScriptS3Bucket: |
  Choose S3 Bucket location
  *Spark*: S3 Bucket where scripts are stored.
  *Hive*: S3 Bucket where the initialization script is stored.
ScriptS3BucketFolder: |
  Specify the S3 folder location.
  *Spark*: S3 Bucket where scripts are stored. Example: `samples/wordcount/scripts/wordcount.py`
  *Hive*: S3 location of the initialization script that you can use to initialize tables prior to running the Hive script. Example: `hive/create_table.sql`
ScriptArguments: |
  Specify the arguments
  *Spark*: Specify array of arguments passed to your main JAR or Python script. Each argument in the array must be separated by a comma. 
    Example:
    ```js
       ["s3://<YOUR_S3_BUCKET_NAME>/wordcount_output", 40000]
    ```
  *Hive*: The S3 URI of the main JAR or Python script in S3 which needs to be executed in the job. Example: s3://<YOUR_S#_BUCKET>/hive/extreme_weather.sql
ScriptSubmitParameters: |
  Specify additional configuration properties for your each job.
    *Spark*: Example: `--hiveconf hive.exec.scratchdir=s3://<>S3_BUCKET>/hive/scratch, --hiveconf hive.metastore.warehouse.dir=s3://<S3_BUCKET>>/hive/warehouse`
    *Hive*: Example: `--conf spark.executor.cores=1 --conf spark.executor.memory=4g --conf spark.driver.cores=1 --conf spark.driver.memory=4g --conf spark.executor.instances=1`
